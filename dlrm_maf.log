[2022-09-16 16:34:35.338] [info] Requesting resources for KT AI Accelerator from the server...
[2022-09-16 16:34:36.358] [info] Initializing the worker daemon for KT AI Accelerator
[2022-09-16 16:34:37.022] [info] [1/1] Connecting to resources on the server (192.168.110.18:24171)...
[2022-09-16 16:34:37.036] [info] Establishing links to the resources...
[2022-09-16 16:34:37.055] [info] KT AI Accelerator is ready to use.
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Using 1 GPU(s)...
model arch:
mlp top arch 3 layers, with input to output dimensions:
[8 4 2 1]
# of interactions
8
mlp bot arch 2 layers, with input to output dimensions:
[4 3 2]
# of features (sparse and dense)
4
dense feature size
4
sparse feature size
2
# of embeddings (= # of sparse features) 3, with dimensions 2x:
[4 3 2]
data (inputs and targets):
mini-batch: 0
tensor([[0.6965, 0.2861, 0.2269, 0.5513],
        [0.7195, 0.4231, 0.9808, 0.6848]])
tensor([[1, 2],
        [1, 1],
        [1, 1]], dtype=torch.int32)
[tensor([1, 0, 1]), tensor([0, 1]), tensor([1, 0])]
tensor([[0.3618],
        [0.2283]])
mini-batch: 1
tensor([[0.2937, 0.6310, 0.0921, 0.4337],
        [0.4309, 0.4937, 0.4258, 0.3123]])
tensor([[1, 2],
        [1, 2],
        [1, 1]], dtype=torch.int32)
[tensor([3, 0, 2]), tensor([1, 1, 2]), tensor([1, 1])]
tensor([[0.6031],
        [0.5451]])
mini-batch: 2
tensor([[0.3428, 0.3041, 0.4170, 0.6813],
        [0.8755, 0.5104, 0.6693, 0.5859]])
tensor([[2, 1],
        [1, 2],
        [1, 1]], dtype=torch.int32)
[tensor([2, 3, 2]), tensor([0, 0, 2]), tensor([1, 1])]
tensor([[0.5568],
        [0.1590]])
initial parameters (weights and bias):
[[-0.34693  0.19553]
 [-0.18123  0.19197]
 [ 0.05438 -0.11105]
 [ 0.42513  0.34167]]
[[-0.16466 -0.52702]
 [-0.22543 -0.11757]
 [ 0.23667  0.57199]]
[[-0.20377  0.3713 ]
 [ 0.13177  0.27111]]
[[-0.16825 -0.58044 -0.39152 -0.64812]
 [ 1.11561  0.0879   0.61481 -0.67743]
 [ 0.09677  0.62959 -0.17907  0.55115]]
[-0.62618 -0.7872   0.21905]
[[-0.23981  0.40607 -1.25093]
 [ 0.45048  1.64331 -0.01557]]
[0.02414 0.12696]
[[-0.76015  0.17397 -0.65541 -0.1746   0.5074  -0.30015  0.20463  0.41345]
 [ 0.1138  -0.55969 -0.13573  0.79993 -0.82672 -0.11259 -0.2254   0.04929]
 [ 0.30546  0.65675 -0.11032  0.33164  0.20402  0.19365 -0.23022 -0.40715]
 [-0.44909 -0.30881  0.13133  0.31066  0.13206 -0.22411  0.73728  0.62007]]
[-0.177   -0.41172  0.06511  0.63365]
[[ 0.19212  0.32132 -0.12244  0.26343]
 [ 0.89174 -0.13837  0.08274  0.14654]]
[ 0.20062 -0.99836]
[[-1.53246 -0.83254]]
[0.16794]
time/loss/accuracy (if enabled):
Finished training it 1/3 of epoch 0, -1.00 ms/it, loss 0.018993
Finished training it 2/3 of epoch 0, -1.00 ms/it, loss 0.029700
Finished training it 3/3 of epoch 0, -1.00 ms/it, loss 0.049903
/home/ubuntu/.conda/envs/k-detr2/lib/python3.8/site-packages/moreh_driver-22.9.0-py3.8.egg/moreh/driver/pytorch/torch/cuda/builtin.py:29: UserWarning: torch.cuda.synchronize() is ignored in Moreh AI Framework. This does not affect the program behavior in most cases. Please contact technical support for further information.
  warnings.warn(
updated parameters (weights and bias):
[[-0.34698  0.19556]
 [-0.18126  0.19205]
 [ 0.05439 -0.11103]
 [ 0.4251   0.34159]]
[[-0.16464 -0.52695]
 [-0.2255  -0.11758]
 [ 0.23668  0.57204]]
[[-0.20388  0.37132]
 [ 0.13175  0.27098]]
[[-0.16825 -0.58044 -0.39152 -0.64812]
 [ 1.11518  0.08764  0.61439 -0.67776]
 [ 0.09677  0.62959 -0.17907  0.55116]]
[-0.62618 -0.78773  0.21905]
[[-0.23981  0.40607 -1.25093]
 [ 0.45048  1.64324 -0.01563]]
[0.02414 0.1269 ]
[[-0.76015  0.17397 -0.65541 -0.1746   0.5074  -0.30015  0.20463  0.41345]
 [ 0.1138  -0.55969 -0.13573  0.79993 -0.82672 -0.11259 -0.2254   0.04929]
 [ 0.30546  0.65666 -0.11032  0.33164  0.20399  0.19363 -0.23022 -0.40716]
 [-0.44909 -0.30864  0.13133  0.31065  0.13211 -0.22405  0.73728  0.62009]]
[-0.177   -0.41172  0.06508  0.63371]
[[ 0.19212  0.32132 -0.12192  0.26336]
 [ 0.89174 -0.13837  0.08274  0.14654]]
[ 0.20084 -0.99836]
[[-1.53243 -0.83254]]
[0.1678]
/home/ubuntu/.conda/envs/k-detr2/lib/python3.8/tempfile.py:816: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp2lfhu8sf'>
  _warnings.warn(warn_message, ResourceWarning)
